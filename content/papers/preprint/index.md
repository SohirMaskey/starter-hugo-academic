---
abstract: Graph neural networks (GNNs) are the primary tool for processing
  graph-structured data. Unfortunately, the most commonly used GNNs, called
  Message Passing Neural Networks (MPNNs) suffer from several fundamental
  limitations. To overcome these limitations, recent works have adapted the idea
  of positional encodings to graph data. This paper draws inspiration from the
  recent success of Laplacian-based positional encoding and defines a novel
  family of positional encoding schemes for graphs. We accomplish this by
  generalizing the optimization problem that defines the Laplace embedding to
  more general dissimilarity functions rather than the 2-norm used in the
  original formulation. This family of positional encodings is then instantiated
  by considering p-norms. We discuss a method for calculating these positional
  encoding schemes, implement it in PyTorch and demonstrate how the resulting
  positional encoding captures different properties of the graph. Furthermore,
  we demonstrate that this novel family of positional encodings can improve the
  expressive power of MPNNs. Lastly, we present preliminary experimental
  results.
slides: ""
url_pdf: http://arxiv.org/pdf/1512.04133v1
publication_types:
  - "1"
authors:
  - admin
  - Ali Parviz
  - Maximilian Thiessen
  - Hannes St√§rk
  - Ylli Sadikaj
  - Haggai Maron
summary: ""
url_dataset: "#"
url_project: ""
publication_short: NeurEPS@NeurIPS
url_source: "#"
url_video: "#"
publication: NeurIPS 2022 Workshop on Symmetry and Geometry in Neural Representations
featured: false
date: 2019-04-07T00:00:00Z
url_slides: ""
title: Generalized Laplacian Positional Encoding for Graph Representation Learning
tags: []
links:
  - name: Custom Link
    url: http://example.org
projects: []
image:
  caption: ""
  focal_point: ""
  preview_only: false
publishDate: 2017-01-01T00:00:00Z
url_poster: "#"
url_code: https://github.com/wowchemy/wowchemy-hugo-themes
doi: ""
---
